{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23a9e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    classification_report,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e921fab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"../02_data\"\n",
    "class_col = \"class\"\n",
    "class_encoding = {\"licit\": 0, \"illicit\": 1}\n",
    "\n",
    "X_train = pd.read_csv(\n",
    "    os.path.join(base_path, \"transactions_train.csv\"), index_col=\"txId\"\n",
    ")\n",
    "X_test = pd.read_csv(os.path.join(base_path, \"transactions_test.csv\"), index_col=\"txId\")\n",
    "\n",
    "X_train = X_train[X_train[class_col] != \"unknown\"].drop(columns=[\"timeStep\"])\n",
    "X_test = X_test[X_test[class_col] != \"unknown\"].drop(columns=[\"timeStep\"])\n",
    "\n",
    "y_train = X_train.pop(\"class\").map(class_encoding)\n",
    "y_test = X_test.pop(\"class\").map(class_encoding)\n",
    "\n",
    "# We standardize since some of the models are highly sensitive to variance.\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd4c7b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"../04_training\"\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.mkdir(output_path)\n",
    "\n",
    "\n",
    "def tune_and_train_model(clf, params):\n",
    "    name = clf.__class__.__name__\n",
    "    print(f\"Training {name}\")\n",
    "\n",
    "    # Avoid recaulating model if it already exists (fairly expensive)\n",
    "    clf_path = os.path.join(output_path, f\"{name}.joblib\")\n",
    "    if os.path.exists(clf_path):\n",
    "        return joblib.load(clf_path)\n",
    "\n",
    "    grid = RandomizedSearchCV(\n",
    "        clf,\n",
    "        params,\n",
    "        cv=5,\n",
    "        n_iter=20,\n",
    "        scoring=\"f1\",\n",
    "        n_jobs=-1,\n",
    "        refit=True,\n",
    "        verbose=True,\n",
    "        random_state=42,\n",
    "    ).fit(X_train, y_train)\n",
    "\n",
    "    # Save to file\n",
    "    with open(os.path.join(output_path, f\"{name}_params.txt\"), \"w\") as f:\n",
    "        json.dump(grid.best_params_, f, indent=2)\n",
    "    joblib.dump(grid.best_estimator_, clf_path)\n",
    "\n",
    "    return grid.best_estimator_\n",
    "\n",
    "\n",
    "def evaluate_model(clf):\n",
    "    name = clf.__class__.__name__\n",
    "\n",
    "    print(f\"Evaluating {name}\")\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_prob = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    with open(os.path.join(output_path, f\"{name}_metrics.txt\"), \"w\") as f:\n",
    "        f.write(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\\n\")\n",
    "        f.write(f\"Precision: {precision_score(y_test, y_pred):.4f}\\n\")\n",
    "        f.write(f\"Recall: {recall_score(y_test, y_pred):.4f}\\n\")\n",
    "        f.write(f\"F1 Score: {f1_score(y_test, y_pred):.4f}\\n\")\n",
    "        f.write(f\"ROC AUC: {roc_auc_score(y_test, y_prob):.4f}\\n\")\n",
    "        f.write(f\"Classification Report:\\n {classification_report(y_test, y_pred)}\\n\")\n",
    "\n",
    "    return clf, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e533a7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RandomForestClassifier\n",
      "Evaluating RandomForestClassifier\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf, rf_pred = evaluate_model(\n",
    "    tune_and_train_model(\n",
    "        RandomForestClassifier(random_state=42),\n",
    "        {\n",
    "            \"n_estimators\": [20, 50, 100, 250],\n",
    "            \"max_depth\": [10, 25, 40, None],\n",
    "            \"min_samples_split\": [2, 10, 20],\n",
    "            \"min_samples_leaf\": [1, 2, 5, 10],\n",
    "        },\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "156be515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LogisticRegression\n",
      "Evaluating LogisticRegression\n"
     ]
    }
   ],
   "source": [
    "lr, lr_pred = evaluate_model(\n",
    "    tune_and_train_model(\n",
    "        LogisticRegression(random_state=42),\n",
    "        {\n",
    "            \"C\": [0.001, 0.01, 0.1, 1, 10],\n",
    "            \"penalty\": [\"l1\", \"l2\"],\n",
    "            \"max_iter\": [100, 1000, None]\n",
    "        },\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbbf857c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_path = \"../03_images\"\n",
    "\n",
    "\n",
    "def plot_embedded_prediction(name, df: pd.DataFrame, preds):\n",
    "    axis1 = df[\"axis1\"]\n",
    "    axis2 = df[\"axis2\"]\n",
    "    classes = df[\"class\"].map({\"licit\": 0, \"illicit\": 1})\n",
    "    _, axes = plt.subplots(len(preds), 1, figsize=(8, 5 * len(preds)), sharex=True, squeeze=True)\n",
    "\n",
    "    for ax, (clf_name, pred) in zip(axes, preds):\n",
    "        mask = classes == pred\n",
    "        ax.scatter(axis1[mask], axis2[mask], c=\"silver\", s=1, label = \"Correct\")\n",
    "        mask = (classes != pred) & (classes == 0)\n",
    "        ax.scatter(axis1[mask], axis2[mask], c=\"blue\", s=1, label=\"False Positive\")\n",
    "        mask = classes != pred & (classes == 1)\n",
    "        ax.scatter(axis1[mask], axis2[mask], c=\"red\", s=1, label=\"False Negative\")\n",
    "\n",
    "        ax.set_title(f\"{clf_name} Predictions: {name} Projection\")\n",
    "        ax.set_xlabel(f\"{name} Axis 1\")\n",
    "        ax.set_ylabel(f\"{name} Axis 2\")\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "    \n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_path, f\"{name.lower()}_projection_2d.png\"))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "preds = [(\"Random Forest\", rf_pred), (\"Logistic Regression\", lr_pred)]\n",
    "plot_embedded_prediction(\n",
    "    \"PCA\", pd.read_csv(os.path.join(embedding_path, \"pca_test_embedding.csv\")), preds\n",
    ")\n",
    "plot_embedded_prediction(\n",
    "    \"UMAP\", pd.read_csv(os.path.join(embedding_path, \"umap_test_embedding.csv\")), preds\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
